{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# README\n",
    "\n",
    "### This file is intended for use as supplementary material for the NeurIPS 2019 submission\n",
    "### \"High Dimensional Causal Discovery\". It acts as a wrapper for the several inference\n",
    "### algorithms that are discussed in the paper. Its primary purpose is to serve as an \n",
    "### oracle for the numerical results presented in Section 4 of the paper. All data \n",
    "### generation used for testing is computed here, so that the examined causal inference\n",
    "### algorithms can be objectively analyzed and compared. Some of the data used for our \n",
    "### zebrafish results (Section 5) is proprietary, and the remainder requires more space \n",
    "### than allowed, however, the data that has been made publically available by its\n",
    "### curators exists here:\n",
    "\n",
    "### https://janelia.figshare.com/articles/Whole-brain_light-sheet_imaging_data/7272617\n",
    "\n",
    "\n",
    "### DEPENDENCIES\n",
    "\n",
    "### This Jupyter notebook requires an array of dependencies in order to fully function \n",
    "### without additional modifications:\n",
    "\n",
    "### A Unix-based OS (MacOS, Linux, etc.) \n",
    "\n",
    "### Python3 Libraries: numpy, scipy, sklearn, joblib, matplotlib, networkx, pickle, dill,\n",
    "### sortedcontainers, argparse, rpy2\n",
    "\n",
    "### In order to run the algorithms implemented in causal-cmd/Tetrad, the current up-to-date\n",
    "### version of the software can be found here:\n",
    "\n",
    "### https://cloud.ccd.pitt.edu/nexus/content/repositories/releases/edu/pitt/dbmi/causal-cmd/1.0.0/\n",
    "\n",
    "### Put the file \"causal-cmd-1.0.0-jar-with-dependencies.jar\" in the same directory as this\n",
    "### file.\n",
    "\n",
    "### Additionally, in order to run the BigQUIC algorithm from this notebook, an up-to-date  \n",
    "### version of R, linked to rpy2, is also required. You must also run the following line\n",
    "### of code from the R console:\n",
    "\n",
    "### install.packages('BigQuic', repos='http://cran.us.r-project.org')\n",
    "\n",
    "### We did not ultimately include GSP in this notebook due to RAM explosion issues during runtime \n",
    "### in the Jupyter notebook, however the current up-to-date version exists here:\n",
    "\n",
    "### https://github.com/uhlerlab/causaldag\n",
    "\n",
    "### The fges-py implementation, as well as the causal-cmd version have been included in the supplementary material\n",
    "### alongside this document.\n",
    "### We do not claim authorship of causal-cmd, and have merely included it for reader convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import scipy.io\n",
    "import random\n",
    "import os\n",
    "import runner\n",
    "import time\n",
    "import rpy2\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects.numpy2ri as numpy2ri\n",
    "from sklearn.covariance import GraphLasso\n",
    "\n",
    "R = rpy2.robjects.r\n",
    "importr('BigQuic')\n",
    "\n",
    "def generate_random_dag(nnodes, avg_degree):\n",
    "    '''Generate a random dag with nnodes nodes and an average degree of avg_degree'''\n",
    "    graph = []\n",
    "    num_edges = float((nnodes * avg_degree) / 2)\n",
    "    tot_edges = float(nnodes*(nnodes-1)/2)   \n",
    "    for i in range(nnodes):\n",
    "        for j in range(i+1, nnodes):\n",
    "            if tot_edges > 0:\n",
    "                odds = float(num_edges / tot_edges)\n",
    "                if random.random() < odds:\n",
    "                    graph.append((i,j))\n",
    "                    num_edges -= 1\n",
    "                tot_edges -= 1\n",
    "    return graph\n",
    "\n",
    "dag = generate_random_dag(10, 2)\n",
    "\n",
    "def generate_data_from_dag(dag, nnodes, sample_size):\n",
    "    '''Given a dag generated by the previous function, generate randomized Gaussian \n",
    "    data from this dag with sample size sample_size'''\n",
    "    dag_dict = {}\n",
    "    parents = {}\n",
    "    for edge in dag:\n",
    "        dag_dict[edge] = random.uniform(0.5,0.7)\n",
    "    for i in range(nnodes):\n",
    "        for j in dag:\n",
    "            if j[0] == i:\n",
    "                if j[1] not in parents:\n",
    "                    parents[j[1]] = {i}\n",
    "                else:\n",
    "                    parents[j[1]].update({i})\n",
    "    for i in range(nnodes):\n",
    "        if i not in parents:\n",
    "            parents[i] = {}\n",
    "    result = np.zeros((sample_size, nnodes))\n",
    "    for i in range(sample_size):\n",
    "        completed_nodes = set()\n",
    "        samples = np.zeros(nnodes)\n",
    "        for k in range(nnodes):\n",
    "            if parents[k] == {}:\n",
    "                samples[k] = np.random.normal()\n",
    "                completed_nodes.add(k)\n",
    "        while (not completed_nodes == set(list(range(nnodes)))):\n",
    "            for j in parents:\n",
    "                if j not in completed_nodes:\n",
    "                    if set(parents[j]).issubset(completed_nodes):\n",
    "                        tot = 0\n",
    "                        for par in parents[j]:\n",
    "                            tot += dag_dict[(par, j)] * samples[par]\n",
    "                        tot +=  np.random.normal()\n",
    "                        samples[j] = tot\n",
    "                        completed_nodes.add(j)\n",
    "        result[i] = samples\n",
    "    np.savetxt('test.tmp' ,result)\n",
    "    return result, dag_dict\n",
    "\n",
    "def compare_graphs_directed(g1, g2):\n",
    "    '''Compute the precision and recall of g1 compared to the ground truth g2\n",
    "    For directed methods only'''\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    for i in g1:\n",
    "        if i in g2:\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            false_positive += 1\n",
    "    for i in g2:\n",
    "        if i not in g1:\n",
    "            false_negative += 1\n",
    "    return (true_positive / (true_positive + false_positive), \n",
    "            true_positive / (true_positive + false_negative))\n",
    "\n",
    "def compare_graphs_undirected(g1, g2):\n",
    "    '''Compute the precision and recall of g1 compared to the ground truth g2\n",
    "    For undirected methods only'''\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    for (i1, i2) in g1:\n",
    "        if (i1, i2) in g2 or (i2, i1) in g2:\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            false_positive += 1\n",
    "    for (i1, i2) in g2:\n",
    "        if (i1, i2) not in g1 and (i2, i1) not in g1:\n",
    "            false_negative += 1\n",
    "    return (true_positive / (true_positive + false_positive), \n",
    "            true_positive / (true_positive + false_negative))\n",
    "\n",
    "def get_graph_from_ccmd_text(filename):\n",
    "    '''Extract graph from causal-cmd output into Python-readable format'''\n",
    "    f = open(filename, 'r') \n",
    "    while f.readline()[:11] != 'Graph Edges':\n",
    "        continue\n",
    "    edge = '0'\n",
    "    edges  = []\n",
    "    # Just string parsing\n",
    "    while edge != '' and str(edge[0])[0] in '0123456789':\n",
    "        edge = (f.readline())\n",
    "        lst = edge.split()\n",
    "        if lst != []:\n",
    "            edge = (int(lst[1][1:]) - 1, int(lst[3][1:]) - 1)\n",
    "            edges.append(edge)\n",
    "    return edges\n",
    "\n",
    "def extract_undir_graph_from_mat(mat, num_edges):\n",
    "    '''Convert a precision matrix into an undirected graph with num_edges edges\n",
    "    by performing binary search over inverse covariance thresholds'''\n",
    "    pres = np.abs(mat)\n",
    "    # Set the bottom triangle of the matrix to zero to prevent repetition\n",
    "    for i in range(len(pres)):\n",
    "        for j in range(len(pres)):\n",
    "            if i >= j:\n",
    "                pres[i][j] = 0\n",
    "    # Perform binary search on covariance thresholding to determine cutoff value\n",
    "    cutoff = 5\n",
    "    split = 2.5\n",
    "    while True:\n",
    "        num = np.sum(pres > cutoff)\n",
    "        if split < 0.000001:\n",
    "            break\n",
    "        elif num > num_edges:\n",
    "            cutoff += split\n",
    "            split /= 2\n",
    "        elif num < num_edges:\n",
    "            cutoff -= split\n",
    "            split /= 2\n",
    "        else: \n",
    "            break\n",
    "    thresh_mat = 1*(pres > cutoff)\n",
    "    edges = []\n",
    "    for ei, i in enumerate(thresh_mat):\n",
    "        for ej, j in enumerate(i):\n",
    "            if j:\n",
    "                edges.append((ei,ej))\n",
    "    return edges\n",
    "\n",
    "\n",
    "def bigquic(mat, alpha):\n",
    "    \"\"\"Wrapper for BigQUIC\"\"\"\n",
    "    r_mat =  numpy2ri.numpy2rpy(mat) \n",
    "    # Run the R program\n",
    "    # Source: https://github.com/gregversteeg/py_bigquic\n",
    "    program_string = 'f <- function(r) {out = BigQuic(X=r, lambda=' + str(alpha) + ', use_ram=TRUE);'\n",
    "    program_string += 'as(out$precision_matrices[[1]], \"matrix\")}'\n",
    "    f = R(program_string)\n",
    "    prec = np.array(f(r_mat))\n",
    "    return prec\n",
    "\n",
    "def test_alg(algorithm='fges-py', nnodes=1000, avg_degree=5, penalty=5, sample_size=1000, alpha=0.01):\n",
    "    '''\n",
    "    Test any algorithm of your choice, varying the hyperparameters:\n",
    "    nnodes: number of nodes in the generated dag\n",
    "    avg_degree: Average degree of the generated dag\n",
    "    sample_oze: Sample size of the data generated from the dag\n",
    "    penalty: Sparsity penalty. Only applies to some algorithms. (fges,fask,pc)\n",
    "    alpha: Regularization term. Only applies to some algorithms. (gLasso, BigQUIC)\n",
    "    '''\n",
    "    dag = generate_random_dag(nnodes, avg_degree)\n",
    "    data = generate_data_from_dag(dag, nnodes, sample_size)[0]\n",
    "    time1 = time.time()\n",
    "    print(\"Algorithm Starting\")\n",
    "    if algorithm == 'fges-py':\n",
    "        runner.main(dataset=\"test.tmp\",save_name=\"fges_results\", sparsity=penalty)\n",
    "        result = list(joblib.load(\"fges_results.pkl\")['graph'].edges)\n",
    "        directed = True\n",
    "    elif algorithm == 'causal-cmd-fges':\n",
    "        os.system('java -jar causal-cmd-1.0.0-jar-with-dependencies.jar  --algorithm fges --data-type continuous --dataset test.tmp --delimiter space --score sem-bic --skip-latest --penaltyDiscount ' + str(float(penalty)) + ' --no-header --prefix results')\n",
    "        result = get_graph_from_ccmd_text('results.txt')\n",
    "        directed = True\n",
    "    elif algorithm == 'fask':\n",
    "        os.system('java -jar causal-cmd-1.0.0-jar-with-dependencies.jar  --algorithm fask --data-type continuous --dataset test.tmp --delimiter space --score sem-bic --skip-latest --penaltyDiscount ' + str(float(penalty)) + ' --no-header --useFasAdjacencies --prefix results')\n",
    "        result = get_graph_from_ccmd_text('results.txt')\n",
    "        directed = True\n",
    "    elif algorithm == 'heut-pc':\n",
    "        os.system('java -jar causal-cmd-1.0.0-jar-with-dependencies.jar --algorithm pc-all --data-type continuous --dataset test.tmp --delimiter space --test sem-bic --skip-latest --penaltyDiscount ' + str(float(penalty)) + ' --no-header --prefix results --stableFAS')\n",
    "        result = get_graph_from_ccmd_text('results.txt')\n",
    "        directed = True\n",
    "    elif algorithm == 'bigquic-R':\n",
    "        prec_mat = bigquic(data, alpha=alpha)\n",
    "        result = extract_undir_graph_from_mat(prec_mat, (nnodes * avg_degree) / 2)\n",
    "        directed = False\n",
    "    elif algorithm == 'glasso-sklearn':\n",
    "        model = GraphLasso(alpha=alpha)\n",
    "        data -= data.mean(axis=0)\n",
    "        stds = np.std(data, axis=0).clip(1e-10)\n",
    "        data /= stds\n",
    "        model.fit(data)\n",
    "        prec_mat = model.precision_\n",
    "        result = extract_undir_graph_from_mat(prec_mat, (nnodes * avg_degree) / 2)\n",
    "        directed = False\n",
    "    time2 = time.time()\n",
    "    if directed:\n",
    "        precision, recall = compare_graphs_directed(result, dag)\n",
    "    else:\n",
    "        precision, recall = compare_graphs_undirected(result, dag)\n",
    "    os.system('rm test.tmp causal-cmd.log results.txt fges_results.pkl')\n",
    "    return precision, recall, (time2 - time1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_alg(algorithm='fges-py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
